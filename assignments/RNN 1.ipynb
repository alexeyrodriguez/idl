{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (7,7) # Make the figures a bit bigger\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  9.8M  100  9.8M    0     0  5772k      0  0:00:01  0:00:01 --:--:-- 5770k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o will_play_text.csv https://commondatastorage.googleapis.com/ckannet-storage/2012-04-24T183403/will_play_text.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment 1 - First Steps.ipynb  RNN 1.ipynb  will_play_text.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1\";\"Henry IV\";;;;\"ACT I\"\r",
      "\r\n",
      "\"2\";\"Henry IV\";;;;\"SCENE I. London. The palace.\"\r",
      "\r\n",
      "\"3\";\"Henry IV\";;;;\"Enter KING HENRY, LORD JOHN OF LANCASTER, the EARL of WESTMORELAND, SIR WALTER BLUNT, and others\"\r",
      "\r\n",
      "\"4\";\"Henry IV\";\"1\";\"1.1.1\";\"KING HENRY IV\";\"So shaken as we are, so wan with care,\"\r",
      "\r\n",
      "\"5\";\"Henry IV\";\"1\";\"1.1.2\";\"KING HENRY IV\";\"Find we a time for frighted peace to pant,\"\r",
      "\r\n",
      "\"6\";\"Henry IV\";\"1\";\"1.1.3\";\"KING HENRY IV\";\"And breathe short-winded accents of new broils\"\r",
      "\r\n",
      "\"7\";\"Henry IV\";\"1\";\"1.1.4\";\"KING HENRY IV\";\"To be commenced in strands afar remote.\"\r",
      "\r\n",
      "\"8\";\"Henry IV\";\"1\";\"1.1.5\";\"KING HENRY IV\";\"No more the thirsty entrance of this soil\"\r",
      "\r\n",
      "\"9\";\"Henry IV\";\"1\";\"1.1.6\";\"KING HENRY IV\";\"Shall daub her lips with her own children's blood;\"\r",
      "\r\n",
      "\"10\";\"Henry IV\";\"1\";\"1.1.7\";\"KING HENRY IV\";\"Nor more shall trenching war channel her fields,\"\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head will_play_text.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('will_play_text.csv', sep=';', header=None, names=['row', 'piece', 'chapter', 'section', 'character', 'line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>piece</th>\n",
       "      <th>chapter</th>\n",
       "      <th>section</th>\n",
       "      <th>character</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACT I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SCENE I. London. The palace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>So shaken as we are, so wan with care,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Find we a time for frighted peace to pant,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.3</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>And breathe short-winded accents of new broils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.4</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>To be commenced in strands afar remote.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.5</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>No more the thirsty entrance of this soil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.6</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Shall daub her lips with her own children's bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Henry IV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1.7</td>\n",
       "      <td>KING HENRY IV</td>\n",
       "      <td>Nor more shall trenching war channel her fields,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row     piece  chapter section      character  \\\n",
       "0    1  Henry IV      NaN     NaN            NaN   \n",
       "1    2  Henry IV      NaN     NaN            NaN   \n",
       "2    3  Henry IV      NaN     NaN            NaN   \n",
       "3    4  Henry IV      1.0   1.1.1  KING HENRY IV   \n",
       "4    5  Henry IV      1.0   1.1.2  KING HENRY IV   \n",
       "5    6  Henry IV      1.0   1.1.3  KING HENRY IV   \n",
       "6    7  Henry IV      1.0   1.1.4  KING HENRY IV   \n",
       "7    8  Henry IV      1.0   1.1.5  KING HENRY IV   \n",
       "8    9  Henry IV      1.0   1.1.6  KING HENRY IV   \n",
       "9   10  Henry IV      1.0   1.1.7  KING HENRY IV   \n",
       "\n",
       "                                                line  \n",
       "0                                              ACT I  \n",
       "1                       SCENE I. London. The palace.  \n",
       "2  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n",
       "3             So shaken as we are, so wan with care,  \n",
       "4         Find we a time for frighted peace to pant,  \n",
       "5     And breathe short-winded accents of new broils  \n",
       "6            To be commenced in strands afar remote.  \n",
       "7          No more the thirsty entrance of this soil  \n",
       "8  Shall daub her lips with her own children's bl...  \n",
       "9   Nor more shall trenching war channel her fields,  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 41, 65, ...,  3, 73, 59],\n",
       "       [ 0, 30, 59, ...,  3, 68, 55],\n",
       "       [ 0, 24, 66, ..., 53, 55, 66],\n",
       "       ..., \n",
       "       [ 0, 27, 52, ..., 65,  3, 60],\n",
       "       [ 0, 40, 55, ..., 65, 58,  3],\n",
       "       [ 0, 45, 55, ...,  3, 64, 55]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = df[~df.character.isnull()].line\n",
    "\n",
    "# mapping\n",
    "letters = ['>'] + list(set(''.join(list(sentences))))\n",
    "nletters = len(letters)\n",
    "\n",
    "bw_mapping = dict(enumerate(letters))\n",
    "fw_mapping = dict([(c, ix) for ix, c in enumerate(letters)])\n",
    "\n",
    "sen_sz = 1 + 30\n",
    "\n",
    "# dataset\n",
    "sentences = [fw_mapping[c] for s in sentences if len(s)>(sen_sz - 1) for c in ['>'] + list(s[:sen_sz - 1])]\n",
    "sentences = np.array(sentences).reshape((len(sentences) / sen_sz, sen_sz))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111389,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df.character.isnull()].line.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87336, 31)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['>',\n",
       " 'F',\n",
       " 'o',\n",
       " 'r',\n",
       " ' ',\n",
       " 'm',\n",
       " 'o',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'b',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'a',\n",
       " 'i',\n",
       " 'd',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[bw_mapping[c] for c in list(sentences[102])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def variable_summaries(var):\n",
    "  \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "  with tf.name_scope('summaries'):\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.summary.scalar('mean', mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "      stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "    tf.summary.scalar('stddev', stddev)\n",
    "    tf.summary.scalar('max', tf.reduce_max(var))\n",
    "    tf.summary.scalar('min', tf.reduce_min(var))\n",
    "    tf.summary.histogram('histogram', var)\n",
    "\n",
    "# From Aylien's blog https://github.com/AYLIEN/gan-intro/blob/master/gan.py\n",
    "def linear(input, output_dim, scope=None, stddev=1.0):\n",
    "    with tf.variable_scope(scope or 'linear'):\n",
    "        with tf.variable_scope('weights'):\n",
    "            w = tf.get_variable(\n",
    "                'w',\n",
    "                [input.get_shape()[1], output_dim],\n",
    "                initializer=tf.random_normal_initializer(stddev=stddev)\n",
    "            )\n",
    "            variable_summaries(w)\n",
    "        with tf.variable_scope('bias'):\n",
    "            b = tf.get_variable(\n",
    "                'b',\n",
    "                [output_dim],\n",
    "                initializer=tf.constant_initializer(0.5)\n",
    "            )\n",
    "            variable_summaries(b)\n",
    "        return tf.matmul(input, w) + b, (w, b)\n",
    "\n",
    "def bilinear(input, state, output_dim, scope=None, stddev=1.0):\n",
    "    with tf.variable_scope(scope or 'linear'):\n",
    "        with tf.variable_scope('input_weights'):\n",
    "            iw = tf.get_variable(\n",
    "                 'iw',\n",
    "                 [input.get_shape()[1], output_dim],\n",
    "                 initializer=tf.random_normal_initializer(stddev=stddev)\n",
    "            )\n",
    "            variable_summaries(iw)\n",
    "        with tf.variable_scope('state_weights'):\n",
    "            sw = tf.get_variable(\n",
    "                 'sw',\n",
    "                 [state.get_shape()[1], output_dim],\n",
    "                 initializer=tf.random_normal_initializer(stddev=stddev)\n",
    "            )\n",
    "            variable_summaries(sw)\n",
    "        with tf.variable_scope('bias'):\n",
    "            b = tf.get_variable(\n",
    "                'b',\n",
    "                [output_dim],\n",
    "                initializer=tf.constant_initializer(0.5)\n",
    "            )\n",
    "            variable_summaries(b)\n",
    "        return tf.matmul(input, iw) + tf.matmul(state, sw) + b, (iw, sw, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_optimize(sess, train, Xs, loss, name='train', steps=1000, optimizer=tf.train.GradientDescentOptimizer(0.5), dict={}, batch_size=100):\n",
    "    train_step = optimizer.minimize(loss)\n",
    "    \n",
    "    # Merge all the summaries and write them out to /tmp/mnist_logs (by default)\n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter('rnn_logs/%s' % name, sess.graph)\n",
    "    \n",
    "    for g, v in optimizer.compute_gradients(loss):\n",
    "        #tf.summary.scalar(\"grad_{}\".format(v.name), tf.norm(g))\n",
    "        #merged = tf.Print(merged, [tf.norm(g)], message=\"grad_{}\".format(v.name))\n",
    "        pass\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(steps):\n",
    "        \n",
    "        # Such a hack\n",
    "        start = (i * batch_size) % train.shape[0]\n",
    "        end = ((i+1) * batch_size) % train.shape[0]\n",
    "        \n",
    "        if start < end:\n",
    "            batch_xs = train[start:end]\n",
    "            dict = dict.copy()# Avoid getting the keys from a different graph\n",
    "            dict[Xs] = batch_xs\n",
    "            summary, _, xloss = sess.run([merged, train_step, loss], feed_dict=dict)\n",
    "            \n",
    "            if i % 500 == 0:\n",
    "                print 'Step {}\\tLoss: {}'.format(i, xloss)\n",
    "\n",
    "            train_writer.add_summary(summary, i)\n",
    "        \n",
    "    train_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_state_size = 512\n",
    "\n",
    "def rnn_text():\n",
    "\n",
    "    init_state = tf.placeholder(tf.float32, [None, hidden_state_size])\n",
    "    hidden_state = init_state\n",
    "\n",
    "    seq_input = tf.placeholder(tf.int64, [None, sen_sz])\n",
    "    enc_seq_input = tf.one_hot(seq_input, nletters) # adds a trailing dimension with the hot encoding\n",
    "\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(sen_sz-1):\n",
    "        x = enc_seq_input[:, i, :]\n",
    "        y = enc_seq_input[:, i+1, :]\n",
    "        \n",
    "        #x = tf.Print(x, [i, tf.argmax(tf.reshape(x, [nletters])), tf.argmax(tf.reshape(y, [nletters]))])\n",
    "        \n",
    "        with tf.variable_scope('step', reuse=i!=0):\n",
    "            hidden_state, _ = bilinear(x, hidden_state, hidden_state_size, 'hl1')\n",
    "            hidden_state = tf.nn.tanh(hidden_state)\n",
    "            output, _ = linear(hidden_state, nletters, 'ol1')\n",
    "\n",
    "        costs.append(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output))\n",
    "        \n",
    "    loss = tf.reduce_mean(costs)\n",
    "    \n",
    "    return seq_input, init_state, loss\n",
    "\n",
    "def rnn_synth_text():\n",
    "\n",
    "    init_state = tf.placeholder(tf.float32, [None, hidden_state_size])\n",
    "    hidden_state = init_state\n",
    "\n",
    "    char_input = tf.placeholder(tf.int64, [None])\n",
    "    x = tf.one_hot(char_input, nletters)\n",
    "    \n",
    "    with tf.variable_scope('step'):\n",
    "        hidden_state, _ = bilinear(x, hidden_state, hidden_state_size, 'hl1')\n",
    "        hidden_state = tf.nn.tanh(hidden_state)\n",
    "        output, _ = linear(hidden_state, nletters, 'ol1')\n",
    "\n",
    "    py = tf.nn.softmax(output)\n",
    "    \n",
    "    return char_input, init_state, py, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\tLoss: 53.9063301086\n",
      "Step 500\tLoss: 30.8396778107\n",
      "Step 1000\tLoss: 21.7353401184\n",
      "Step 1500\tLoss: 15.4579753876\n",
      "Step 2000\tLoss: 10.5770626068\n",
      "Step 2500\tLoss: 6.52960062027\n",
      "Step 3000\tLoss: 4.04687929153\n",
      "Step 3500\tLoss: 3.14851665497\n",
      "Step 4000\tLoss: 3.05737304688\n",
      "Step 4500\tLoss: 2.99856805801\n",
      "Step 5000\tLoss: 2.99920678139\n",
      "Step 5500\tLoss: 2.97211074829\n",
      "Step 6000\tLoss: 2.96686792374\n",
      "Step 6500\tLoss: 2.92390537262\n",
      "Step 7000\tLoss: 2.94415283203\n",
      "Step 7500\tLoss: 2.96437168121\n",
      "Step 8000\tLoss: 2.94192743301\n",
      "Step 8500\tLoss: 2.98177599907\n",
      "Step 9000\tLoss: 2.98598623276\n",
      "Step 9500\tLoss: 2.96574926376\n",
      "Step 10000\tLoss: 2.9784052372\n"
     ]
    }
   ],
   "source": [
    "#batch_size = 128\n",
    "#batch_size = 1024\n",
    "batch_size = 512\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        Xs, init_state, loss = rnn_text()\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        my_optimize(sess,\n",
    "                    sentences,\n",
    "                    Xs,\n",
    "                    loss,\n",
    "                    steps=10001,\n",
    "                    name='train-1',\n",
    "                    batch_size=batch_size,\n",
    "                    dict={init_state: np.zeros((batch_size, hidden_state_size))},\n",
    "                    optimizer=optimizer)\n",
    "        \n",
    "        tf.train.Saver().save(sess, 'model-rnn-v2-1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model-rnn-v2-1.ckpt\n",
      ">Atwrowtoi ae  aalssrwrr themeybrar elet-sle  sfo fl o beue,iiyo hp  pkpheech  dgAlltuahtrt ewato k   'nUpstftle-id,  ,ovuiougerhLdhoe  tfo aa ofuuishifhoc hv ilers ivnefnty piadtsyle  kshm tr ji!r i gfes  uytnu wieft pruddaid ath sowoumhoendt ofn Yut g .httiauestene be iertulu,hetw rroelch 'ry tgens hhgpmaeylt c'o i f tdesno  oote no sefthan eahoecdd: eea hai r tay  t unsrhyoibnke el  dhfns rk; eor emdwiimny e et thay6 bieieat eaheb  eye''thitr c;f u ri;iytnsrity uay d  r ?hn dt t ; ooeabhl dwrc\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        char_input, init_state, p_output, out_state = rnn_synth_text()\n",
    "        \n",
    "        tf.train.Saver().restore(sess, 'model-rnn-v2-1.ckpt')\n",
    "        #sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        res = ['>']\n",
    "        cur_char = fw_mapping['>']\n",
    "        cur_state = np.zeros((batch_size, hidden_state_size))\n",
    "\n",
    "        for _ in range(500):#sen_sz - 1):        \n",
    "            ps, state = sess.run([p_output, out_state],\n",
    "                                 feed_dict={char_input: np.array([cur_char]), init_state: cur_state})\n",
    "            #cur_char = np.argmax(ps)\n",
    "            cur_char = np.random.choice(nletters, p=ps.reshape(nletters))\n",
    "            cur_state = state\n",
    "            res.append(bw_mapping[cur_char])\n",
    "        \n",
    "        print ''.join(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
